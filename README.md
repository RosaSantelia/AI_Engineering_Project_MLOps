# AI_Engineering_Projects_MLOps
My AI Engineering Master's Projects - MLOps

# Documentazione Tecnica del Progetto di Sentiment Analysis

Questo progetto implementa un sistema di analisi del sentiment utilizzando un modello pre-addestrato cardiffnlp/twitter-roberta-base-sentiment-latest di HuggingFace.

Il sistema Ã¨ organizzato in un flusso MLOps che comprende:

- Addestramento e valutazione del modello

- Deploy su HuggingFace Hub

- Pipeline di monitoraggio automatico per valutare periodicamente le performance.


ğŸ“‚ Struttura del progetto

La struttura del progetto Ã¨ organizzata in modo modulare per separare le diverse fasi di sviluppo e deployment:

.
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ ci-cd.yml
â”‚       â””â”€â”€ monitoring.yml
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ evaluate.py
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ model.py
â”‚   â””â”€â”€ schema.py
â”œâ”€â”€ data/
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ TROUBLESHOOTING.md
â”œâ”€â”€ monitoring/
â”‚   â”œâ”€â”€ reports/
â”‚   â””â”€â”€ monitoring.py
â”œâ”€â”€ rosa-twitter-sentiment/
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ pytest.ini
â”‚   â”œâ”€â”€ test_api.py
â”‚   â””â”€â”€ test_model.py
â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ push_to_hub.py
â”‚   â””â”€â”€ train.py
â”œâ”€â”€ .gitignore
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ environment.yml
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ run_tests.sh
â””â”€â”€ setup_conda.sh

app/: Contiene il codice dell'API (FastAPI) e la logica del modello.

training/: Script per l'addestramento e la valutazione del modello, inclusa la logica per il push su Hugging Face.

monitoring/: Script per il monitoraggio continuo delle performance del modello.

tests/: Test unitari e di integrazione per l'API e il modello.

.github/workflows/: File di configurazione per le pipeline di GitHub Actions (CI/CD e Monitoraggio).

Dockerfile: Definizione dell'ambiente containerizzato per l'applicazione.

requirements.txt: Elenco delle dipendenze Python del progetto.

âš™ï¸ Installazione e configurazione

1ï¸âƒ£ Clonare il repository

bash
git clone https://github.com/RosaSantelia/AI_Engineering_Projects_MLOps_rivisto.git
cd AI_Engineering_Projects_MLOps_rivisto

2ï¸âƒ£ Creare e attivare un ambiente Conda

bash
conda create -n sentiment python=3.10
conda activate sentiment

3ï¸âƒ£ Installare le dipendenze

bash
pip install -r requirements.txt


ğŸš€ Esecuzione in locale

Addestrare e valutare il modello

bash
python training/train.py

Monitoraggio locale

bash
python monitoring/monitoring.py

ğŸ³ Esecuzione con Docker

bash
docker build -t sentiment-analysis .
docker run --rm sentiment-analysis

ğŸ”„ Pipeline CI/CD

Il file .github/workflows/ci-cd.yml gestisce:

- Test unitari con pytest

- Addestramento del modello

- Deploy automatico su HuggingFace Hub

ğŸ“ˆ Pipeline di monitoraggio Automatico

Il file .github/workflows/monitoring.yml esegue automaticamente:

- Ogni commit su main

- Ogni giorno alle 2:00 UTC

- Su richiesta manuale

Si tratta di un modulo di monitoraggio continuo per valutare le performance del modello di analisi del sentiment su dati di test o reali.

- Lo script `monitoring/monitoring.py` esegue predizioni batch, salva i risultati in CSV, genera matrici di confusione e un report HTML.

- La pipeline Ã¨ automatizzata tramite GitHub Actions (`.github/workflows/monitoring.yml`), eseguita:
  - Su ogni push al branch `main`
  - Ogni giorno alle 2:00 UTC
  - Manualmente tramite trigger manuale

I report sono caricati come artifact scaricabili dallâ€™interfaccia Actions di GitHub.

### Avvio manuale del monitoraggio

Dal tab **Actions** su GitHub, seleziona il workflow **Monitoring TweetEval** e clicca su **Run workflow**.


ğŸ“– Guida rapida per utenti finali
Inserisci il testo che vuoi analizzare nel modello

Ottieni la classificazione: positive, neutral, negative

Consulta i log in data/sentiment_log.csv per vedere risultati e confronto con etichette reali

ğŸ“Š Esempio di output
Esempio di predizione sentiment:

plaintext
Input: "I love working with this team!"
Predicted: positive
True label: positive

â“ FAQ
1. Che modello viene usato?
cardiffnlp/twitter-roberta-base-sentiment-latest di HuggingFace.

2. Come viene testato?
Con dataset pubblico TweetEval.

3. Qual Ã¨ l'ambiente di sviluppo e testing?
La fase di sviluppo Ã¨ stata testata utilizzando Conda come ambiente virtuale.
Successivamente, il progetto Ã¨ stato containerizzato con Docker per garantire portabilitÃ .

4. Come posso avviare il monitoraggio manualmente?
Dalla sezione Actions di GitHub, selezionare il workflow Monitoring TweetEval e cliccare su Run workflow.